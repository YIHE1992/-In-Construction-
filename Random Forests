from tqdm import tqdm
from time import sleep
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
from sklearn.base import TransformerMixin

# class DataFrameImputer(TransformerMixin): # Encode the N/A data in dataframe
#     def __init__(self):
#         '''Impute missing values:
#         1. Columns of dtype object are imputed with the most frequent value in column.
#         2. Columns of other types are imputed with mean of column.'''
#     def fit(self, X, y=None):
#         self.fill = pd.Series([X[c].value_counts().index[0]
#             if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],
#             index=X.columns)
#         return self
#     def transform(self, X, y=None):
#         return X.fillna(self.fill)

df = pd.read_csv('./10YearsData.csv')

df['Distraction_Label'] = df['Distraction_Label'].replace('Internal', 'NaN') # Swich to binary labelled classification problem

le = preprocessing.LabelEncoder()

int_list = ['CRASH_YEAR', 'CR_MONTH', 'HIT_AND_RUN', 'PEDESTRIAN']
for col in tqdm(int_list):
    df[str(col)] = df[str(col)].dropna().apply(lambda x: int(x) )
    df[str(col)]=df[str(col)].fillna(100)
    df[str(col)] = le.fit_transform(df[str(col)])
    sleep(0.1)

for items in tqdm(df.columns):
    if df.dtypes[str(items)] == 'object':
        df[str(items)]=df[str(items)].fillna('NaN')
        df[str(items)] = le.fit_transform(df[str(items)])
        sleep(0.1)

#df['Distraction_Label'] = df['Distraction_Label'].replace(1, 2)
#print(df['Distraction_Label'].value_counts())
# Hide the label for internal_distraction or external_distraction for each time
# After label encoding, 0, 1, 2 stands for none_distraction, internal_distraction and external_distraction, respectively

clf = RandomForestClassifier(n_estimators = 300,
                             n_jobs = 2,
                             criterion = 'entropy',
                             max_features = 'sqrt',
                             max_depth = 30,
                             oob_score = True)

features = ['ALIGNMENT_CD', 'CRASH_YEAR', 'CR_MONTH', 'DAY_OF_WK', 'DR_SEX',
            'HIT_AND_RUN', 'LIGHTING_CD', 'LOC_TYPE_CD', 'PEDESTRIAN',
            'PRI_CONTRIB_FAC_CD', 'ROAD_COND_CD', 'ROAD_TYPE_CD', 'SEVERITY_CD',
            'SURF_COND_CD', 'SURF_TYPE_CD', 'WEATHER_CD', 'city_level', 'age_group',
            'crash_time', 'vehicle_type', 'From_Louisiana', 'vehicle_year',
            'num_occupant', 'num_vehicle', 'aggressive_driving',
            'drive_condition', 'manner_of_collision']

X = df[features]
y = df['Distraction_Label']
clf.fit(X, y)

print('OOB_Accuracy:')
print(clf.oob_score_)         

Attributes_Importance = pd.DataFrame({'Attributes': features,'OOB_Importance':np.round(clf.feature_importances_,3)})
Attributes_Importance = Attributes_Importance.sort_values('OOB_Importance',ascending=False).set_index('Attributes')
print(Attributes_Importance)
Attributes_Importance.plot.bar()
